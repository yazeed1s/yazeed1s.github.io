<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>Yazeed&#x27;s Blog - CXL</title>
    <subtitle>Notes on systems and low-level software.</subtitle>
    <link rel="self" type="application/atom+xml" href="https://yazeed1s.github.io/tags/cxl/atom.xml"/>
    <link rel="alternate" type="text/html" href="https://yazeed1s.github.io"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2026-01-12T00:00:00+00:00</updated>
    <id>https://yazeed1s.github.io/tags/cxl/atom.xml</id>
    <entry xml:lang="en">
        <title>CXL: Compute Express Link</title>
        <published>2026-01-12T00:00:00+00:00</published>
        <updated>2026-01-12T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://yazeed1s.github.io/posts/cxl/"/>
        <id>https://yazeed1s.github.io/posts/cxl/</id>
        
        <content type="html" xml:base="https://yazeed1s.github.io/posts/cxl/">&lt;hr &#x2F;&gt;
&lt;p&gt;CXL is the thing I keep seeing in memory disaggregation discussions that &lt;em&gt;isn&#x27;t&lt;&#x2F;em&gt; RDMA.&lt;&#x2F;p&gt;
&lt;p&gt;The core idea is simple:&lt;&#x2F;p&gt;
&lt;p&gt;&lt;strong&gt;CXL lets a CPU talk to devices over PCIe as if some of that device memory is just &quot;more memory&quot; (with cache coherence), not just DMA behind a driver.&lt;&#x2F;strong&gt;&lt;&#x2F;p&gt;
&lt;p&gt;That sounds like magic until you remember the trade-off: it&#x27;s still farther than local DRAM. You&#x27;re buying capacity (and sometimes sharing&#x2F;pooling) by paying extra latency and giving the OS a harder placement problem.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;what-cxl-actually-adds&quot;&gt;what cxl actually adds&lt;&#x2F;h2&gt;
&lt;p&gt;PCIe already lets devices do DMA. That&#x27;s not the interesting part.&lt;&#x2F;p&gt;
&lt;p&gt;The interesting part is &lt;strong&gt;coherence + memory semantics&lt;&#x2F;strong&gt;:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;With plain PCIe, the host talks to devices via MMIO, and devices talk to host memory via DMA. You can move bytes around, but it doesn&#x27;t look like &quot;shared memory&quot; (and devices don&#x27;t get to participate as coherent caching agents).&lt;&#x2F;li&gt;
&lt;li&gt;With CXL, the link can carry transactions that participate in the host&#x27;s coherency domain (depending on mode&#x2F;device), so &quot;who sees which bytes when&quot; becomes something hardware can help enforce.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;This is why CXL is pitched as a &lt;em&gt;memory&lt;&#x2F;em&gt; interconnect, not just an I&#x2F;O bus.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;the-three-protocols-the-only-ones-worth-remembering&quot;&gt;the three protocols (the only ones worth remembering)&lt;&#x2F;h2&gt;
&lt;p&gt;CXL isn&#x27;t one protocol, it&#x27;s three riding on top of PCIe:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;CXL.io&lt;&#x2F;strong&gt;: the boring compatibility layer (enumeration, config space, interrupts). Basically &quot;PCIe-like.&quot;&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;CXL.cache&lt;&#x2F;strong&gt;: lets a device cache host memory coherently (device acts like a coherent agent).&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;CXL.mem&lt;&#x2F;strong&gt;: lets the host access device-attached memory with load&#x2F;store semantics (device memory looks like memory, not an I&#x2F;O buffer).&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;If you only care about memory expansion, &lt;strong&gt;CXL.mem&lt;&#x2F;strong&gt; is the star.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;device-types-why-type-3-shows-up-everywhere&quot;&gt;device types (why &quot;type 3&quot; shows up everywhere)&lt;&#x2F;h2&gt;
&lt;p&gt;The spec groups devices into types. You don&#x27;t need the full taxonomy, just the mental model:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Type 1&#x2F;2&lt;&#x2F;strong&gt;: accelerators that want coherency (think &quot;devices that want to touch host memory without fighting the cache hierarchy&quot;).&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Type 3&lt;&#x2F;strong&gt;: &lt;strong&gt;memory expanders&lt;&#x2F;strong&gt;. This is the disaggregation-adjacent one: plug more capacity behind the link and make it usable by the host.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Type 3 is where the &quot;add memory without adding sockets&quot; story comes from.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;what-this-looks-like-to-software&quot;&gt;what this looks like to software&lt;&#x2F;h2&gt;
&lt;p&gt;If CXL is doing its job, &lt;em&gt;applications don&#x27;t change&lt;&#x2F;em&gt;, but the OS has new headaches.&lt;&#x2F;p&gt;
&lt;p&gt;In a typical &quot;memory expansion&quot; setup, CXL memory shows up as:&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;a new pool of capacity the kernel can allocate from&lt;&#x2F;li&gt;
&lt;li&gt;often with NUMA-like properties (different latency&#x2F;bandwidth than local DRAM)&lt;&#x2F;li&gt;
&lt;li&gt;sometimes managed as a lower tier (hot things stay local, colder things spill)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;So the system-level question becomes:&lt;&#x2F;p&gt;
&lt;blockquote&gt;
&lt;p&gt;&quot;Which bytes should live in local DRAM, and which bytes can tolerate being slower?&quot;&lt;&#x2F;p&gt;
&lt;&#x2F;blockquote&gt;
&lt;p&gt;If you let the OS guess, you get &quot;it works, but sometimes it hurts.&quot; If you want predictable performance, you usually need policies: NUMA placement, tiering, explicit pinning, or application-level caching.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;cxl-vs-rdma-why-they-feel-similar-and-why-they-re-not&quot;&gt;cxl vs rdma (why they feel similar and why they&#x27;re not)&lt;&#x2F;h2&gt;
&lt;p&gt;Both get used to talk about &quot;remote memory.&quot; The similarity ends there.&lt;&#x2F;p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;RDMA&lt;&#x2F;strong&gt;: you explicitly issue operations over the network (READ&#x2F;WRITE&#x2F;SEND). It&#x27;s fast (microseconds), but it&#x27;s still a network, and you still build protocols on top.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;CXL&lt;&#x2F;strong&gt;: the CPU can issue load&#x2F;stores into device memory, and hardware can help keep things coherent. It&#x27;s closer to &quot;NUMA, but farther.&quot;&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;p&gt;Also: CXL is a PCIe link&#x2F;fabric. It&#x27;s built for short-reach inside a server (and maybe rack-scale switching), not &quot;put it on Ethernet and forget about it.&quot;&lt;&#x2F;p&gt;
&lt;p&gt;RDMA is a way to move bytes fast. CXL is a way to make &lt;em&gt;some&lt;&#x2F;em&gt; bytes look like memory.&lt;&#x2F;p&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;where-cxl-wins&quot;&gt;where cxl wins&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Capacity expansion without a bigger server.&lt;&#x2F;strong&gt; You want more memory, but you don&#x27;t want another socket just to get more DIMM slots.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Tiered memory.&lt;&#x2F;strong&gt; You have hot working sets and cold-but-still-useful data. CXL can be the &quot;bigger, slower tier&quot; that beats going to SSD.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Disaggregation building block.&lt;&#x2F;strong&gt; If you ever want pooled memory, you need something like CXL on the inside before you can make the outside story real.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;h2 id=&quot;where-it-hurts&quot;&gt;where it hurts&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Latency-sensitive hot paths.&lt;&#x2F;strong&gt; If your workload is dominated by pointer-chasing and cache misses, adding a slower tier can destroy tail latency.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Bandwidth and congestion.&lt;&#x2F;strong&gt; It&#x27;s easy to sell &quot;more capacity.&quot; It&#x27;s harder to deliver &quot;more bandwidth&quot; when many cores start leaning on the same link&#x2F;switch.&lt;&#x2F;li&gt;
&lt;li&gt;&lt;strong&gt;Software maturity and policy.&lt;&#x2F;strong&gt; You can make it work without app changes, but getting good performance is a placement problem, and placement is where systems go to die.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;notes&quot;&gt;notes&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;If you remember one sentence: CXL is &quot;PCIe, but with coherence and memory semantics.&quot;&lt;&#x2F;li&gt;
&lt;li&gt;CXL doesn&#x27;t eliminate NUMA; it gives you a new kind of NUMA-shaped problem.&lt;&#x2F;li&gt;
&lt;li&gt;The exciting part (pooling&#x2F;sharing across a fabric) is also the part with the most sharp edges: security, isolation, failure handling, and who gets to be coherent with whom.&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
</feed>
