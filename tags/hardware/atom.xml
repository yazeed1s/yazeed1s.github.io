<?xml version="1.0" encoding="UTF-8"?>
<feed xmlns="http://www.w3.org/2005/Atom" xml:lang="en">
    <title>Yazeed&#x27;s Blog - Hardware</title>
    <subtitle>Notes on systems and low-level software.</subtitle>
    <link rel="self" type="application/atom+xml" href="https://yazeed1s.github.io/tags/hardware/atom.xml"/>
    <link rel="alternate" type="text/html" href="https://yazeed1s.github.io"/>
    <generator uri="https://www.getzola.org/">Zola</generator>
    <updated>2025-03-23T00:00:00+00:00</updated>
    <id>https://yazeed1s.github.io/tags/hardware/atom.xml</id>
    <entry xml:lang="en">
        <title>CXL: Compute Express Link</title>
        <published>2025-03-23T00:00:00+00:00</published>
        <updated>2025-03-23T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://yazeed1s.github.io/posts/cxl/"/>
        <id>https://yazeed1s.github.io/posts/cxl/</id>
        
        <content type="html" xml:base="https://yazeed1s.github.io/posts/cxl/">&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;What is CXL?&lt;&#x2F;li&gt;
&lt;li&gt;Why a new interconnect? (PCIe limitations for memory)&lt;&#x2F;li&gt;
&lt;li&gt;Industry adoption (Intel, AMD, ARM, etc.)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;cxl-vs-existing-technologies&quot;&gt;CXL vs Existing Technologies&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;CXL vs PCIe&lt;&#x2F;li&gt;
&lt;li&gt;CXL vs RDMA (link to rdma.md)&lt;&#x2F;li&gt;
&lt;li&gt;CXL vs NUMA&lt;&#x2F;li&gt;
&lt;li&gt;Latency and bandwidth comparison&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;cxl-protocol-types&quot;&gt;CXL Protocol Types&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;CXL.io (PCIe compatibility)&lt;&#x2F;li&gt;
&lt;li&gt;CXL.cache (cache coherent access)&lt;&#x2F;li&gt;
&lt;li&gt;CXL.mem (memory access)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;cxl-device-types&quot;&gt;CXL Device Types&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Type 1: Accelerators (cache coherent)&lt;&#x2F;li&gt;
&lt;li&gt;Type 2: Accelerators with memory&lt;&#x2F;li&gt;
&lt;li&gt;Type 3: Memory expanders&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;memory-expansion-use-cases&quot;&gt;Memory Expansion Use Cases&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Adding memory to existing servers&lt;&#x2F;li&gt;
&lt;li&gt;Memory pooling&lt;&#x2F;li&gt;
&lt;li&gt;Tiered memory (fast local + slower CXL)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;software-support&quot;&gt;Software Support&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Linux kernel support&lt;&#x2F;li&gt;
&lt;li&gt;Memory hotplug&lt;&#x2F;li&gt;
&lt;li&gt;NUMA integration&lt;&#x2F;li&gt;
&lt;li&gt;Application transparency&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;cxl-2-0-and-3-0&quot;&gt;CXL 2.0 and 3.0&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Switching and pooling&lt;&#x2F;li&gt;
&lt;li&gt;Memory sharing&lt;&#x2F;li&gt;
&lt;li&gt;What&#x27;s new in each version&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;challenges&quot;&gt;Challenges&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Latency overhead vs local DRAM&lt;&#x2F;li&gt;
&lt;li&gt;Software ecosystem maturity&lt;&#x2F;li&gt;
&lt;li&gt;Cost&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;CXL&#x27;s role in memory disaggregation&lt;&#x2F;li&gt;
&lt;li&gt;Future of data center memory&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;references&quot;&gt;References&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;CXL specification&lt;&#x2F;li&gt;
&lt;li&gt;Industry whitepapers&lt;&#x2F;li&gt;
&lt;li&gt;Research papers&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>Memory Disaggregation: Decoupling Memory from Compute</title>
        <published>2025-03-23T00:00:00+00:00</published>
        <updated>2025-03-23T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://yazeed1s.github.io/posts/memory-disaggregation/"/>
        <id>https://yazeed1s.github.io/posts/memory-disaggregation/</id>
        
        <content type="html" xml:base="https://yazeed1s.github.io/posts/memory-disaggregation/">&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;What is memory disaggregation?&lt;&#x2F;li&gt;
&lt;li&gt;Why do we need it? (memory stranding, resource utilization)&lt;&#x2F;li&gt;
&lt;li&gt;The shift from monolithic servers to disaggregated architectures&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;the-problem-with-traditional-memory&quot;&gt;The Problem with Traditional Memory&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Memory tied to individual servers&lt;&#x2F;li&gt;
&lt;li&gt;Stranded memory (unused but unavailable to other nodes)&lt;&#x2F;li&gt;
&lt;li&gt;Over-provisioning vs under-utilization&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;how-disaggregation-works&quot;&gt;How Disaggregation Works&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Separating memory pools from compute pools&lt;&#x2F;li&gt;
&lt;li&gt;Remote memory access mechanisms&lt;&#x2F;li&gt;
&lt;li&gt;Latency considerations&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;key-technologies&quot;&gt;Key Technologies&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;RDMA (link to rdma.md)&lt;&#x2F;li&gt;
&lt;li&gt;CXL (link to cxl.md)&lt;&#x2F;li&gt;
&lt;li&gt;Network fabrics&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;trade-offs&quot;&gt;Trade-offs&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Latency vs utilization&lt;&#x2F;li&gt;
&lt;li&gt;Complexity vs flexibility&lt;&#x2F;li&gt;
&lt;li&gt;When disaggregation makes sense&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Current state of adoption&lt;&#x2F;li&gt;
&lt;li&gt;Future directions&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;references&quot;&gt;References&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Papers to cite&lt;&#x2F;li&gt;
&lt;li&gt;Further reading&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
    <entry xml:lang="en">
        <title>RDMA: Remote Direct Memory Access</title>
        <published>2025-03-23T00:00:00+00:00</published>
        <updated>2025-03-23T00:00:00+00:00</updated>
        
        <author>
          <name>
            
              Unknown
            
          </name>
        </author>
        
        <link rel="alternate" type="text/html" href="https://yazeed1s.github.io/posts/rdma/"/>
        <id>https://yazeed1s.github.io/posts/rdma/</id>
        
        <content type="html" xml:base="https://yazeed1s.github.io/posts/rdma/">&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;introduction&quot;&gt;Introduction&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;What is RDMA?&lt;&#x2F;li&gt;
&lt;li&gt;Why it matters (low latency, high throughput, zero CPU copy)&lt;&#x2F;li&gt;
&lt;li&gt;Where it&#x27;s used (HPC, data centers, storage)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;traditional-networking-vs-rdma&quot;&gt;Traditional Networking vs RDMA&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;TCP&#x2F;IP stack overhead&lt;&#x2F;li&gt;
&lt;li&gt;Kernel bypass&lt;&#x2F;li&gt;
&lt;li&gt;Zero-copy transfers&lt;&#x2F;li&gt;
&lt;li&gt;CPU involvement comparison&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;rdma-technologies&quot;&gt;RDMA Technologies&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;InfiniBand&lt;&#x2F;li&gt;
&lt;li&gt;RoCE (RDMA over Converged Ethernet)&lt;&#x2F;li&gt;
&lt;li&gt;iWARP&lt;&#x2F;li&gt;
&lt;li&gt;Comparison table&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;key-concepts&quot;&gt;Key Concepts&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Queue Pairs (QP)&lt;&#x2F;li&gt;
&lt;li&gt;Completion Queues (CQ)&lt;&#x2F;li&gt;
&lt;li&gt;Memory Regions (MR)&lt;&#x2F;li&gt;
&lt;li&gt;Protection Domains (PD)&lt;&#x2F;li&gt;
&lt;li&gt;Verbs API&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;rdma-operations&quot;&gt;RDMA Operations&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Send&#x2F;Receive&lt;&#x2F;li&gt;
&lt;li&gt;RDMA Read&lt;&#x2F;li&gt;
&lt;li&gt;RDMA Write&lt;&#x2F;li&gt;
&lt;li&gt;Atomic operations&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;programming-rdma&quot;&gt;Programming RDMA&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;libibverbs basics&lt;&#x2F;li&gt;
&lt;li&gt;Simple example: connection setup&lt;&#x2F;li&gt;
&lt;li&gt;One-sided vs two-sided operations&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;use-cases&quot;&gt;Use Cases&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Distributed storage (Ceph, SPDK)&lt;&#x2F;li&gt;
&lt;li&gt;Databases&lt;&#x2F;li&gt;
&lt;li&gt;Machine learning training&lt;&#x2F;li&gt;
&lt;li&gt;Memory disaggregation (link to memory-disaggregation.md)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;challenges&quot;&gt;Challenges&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;Complex programming model&lt;&#x2F;li&gt;
&lt;li&gt;Hardware requirements&lt;&#x2F;li&gt;
&lt;li&gt;Debugging difficulties&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;conclusion&quot;&gt;Conclusion&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;When to use RDMA&lt;&#x2F;li&gt;
&lt;li&gt;Future: CXL vs RDMA (link to cxl.md)&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
&lt;hr &#x2F;&gt;
&lt;h2 id=&quot;references&quot;&gt;References&lt;&#x2F;h2&gt;
&lt;ul&gt;
&lt;li&gt;RDMA programming guides&lt;&#x2F;li&gt;
&lt;li&gt;Mellanox&#x2F;NVIDIA documentation&lt;&#x2F;li&gt;
&lt;&#x2F;ul&gt;
</content>
        
    </entry>
</feed>
